{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, inspect, Float\n",
    "\n",
    "@functions_framework.http\n",
    "def insert():\n",
    "  connection_string = connection()\n",
    "  push_city_data_to_sql()\n",
    "  push_weather_data_to_sql()\n",
    "  push_airport_data_to_sql()\n",
    "  push_cities_airports_to_sql()\n",
    "  push_flights_datad_to_sql()\n",
    "  return \"successfully updated\"\n",
    "\n",
    "\n",
    "# def connection():\n",
    "#   connection_name = \"cogent-bison-417011:europe-west1:wbs-mysql-db\"\n",
    "#   db_user = \"root\"\n",
    "#   db_password = \"googlecloudjau\"\n",
    "#   schema_name = \"gans\"\n",
    "\n",
    "#   driver_name = 'mysql+pymysql'\n",
    "#   query_string = {\"unix_socket\": f\"/cloudsql/{connection_name}\"}\n",
    "\n",
    "#   db = sqlalchemy.create_engine(\n",
    "#       sqlalchemy.engine.url.URL(\n",
    "#           drivername = driver_name,\n",
    "#           username = db_user,\n",
    "#           password = db_password,\n",
    "#           database = schema_name,\n",
    "#           query = query_string,\n",
    "#       )\n",
    "#   )\n",
    "#   return db\n",
    "\n",
    "def connection():\n",
    "        schema = \"gans\"\n",
    "        host = \"23.251.142.169\" # Change this to your instance's IP\n",
    "        user = \"root\"\n",
    "        password = \"googlecloudjau\" # Your database password goes here\n",
    "        port = 3306\n",
    "        connection_string =  f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "        return connection_string\n",
    "\n",
    "def push_city_data_to_sql():\n",
    "\n",
    "  API_key = \"81f1a5b752c4569a954655d748508db5\"\n",
    "  cities = [\"Berlin\", \"München\", \"Hamburg\", \"Bremen\"]\n",
    "  country_code = \"DE\"\n",
    "  cities_dict = {\"city_id\": [], \"city\": [], \"country\": [],\"population\": [], \"lat\": [], \"lon\": [], \"elevation_[m]\": []}\n",
    "\n",
    "  for city in cities:\n",
    "\n",
    "    url = f\" https://api.openweathermap.org/data/2.5/forecast?q={city},{country_code}&appid={API_key}&units=metric\"\n",
    "    openweather_raw = requests.get(url).json()\n",
    "\n",
    "    if openweather_raw[\"cod\"] == \"200\":\n",
    "\n",
    "      cities_dict[\"city_id\"].append(openweather_raw[\"city\"][\"id\"])\n",
    "      cities_dict[\"city\"].append(openweather_raw[\"city\"][\"name\"])\n",
    "      cities_dict[\"country\"].append(openweather_raw[\"city\"][\"country\"])\n",
    "      cities_dict[\"lat\"].append(openweather_raw[\"city\"][\"coord\"][\"lat\"])\n",
    "      cities_dict[\"lon\"].append(openweather_raw[\"city\"][\"coord\"][\"lon\"])\n",
    "\n",
    "      #webscrape\n",
    "      response = requests.get(f\"https://en.wikipedia.org/wiki/{city}\")\n",
    "      soup = BeautifulSoup(response.content, 'html.parser')\n",
    "      infobox = soup.find(\"table\", {\"class\": \"infobox ib-settlement vcard\"})\n",
    "\n",
    "      if infobox:\n",
    "        # Search for the header containing population information\n",
    "        population_data = infobox.find(string=\"Population\")\n",
    "\n",
    "        # Extract the population value if found, format number and add to list\n",
    "        if population_data:\n",
    "              population = population_data.find_next(\"td\").get_text().strip().replace(\",\", \"\")\n",
    "              cities_dict[\"population\"].append(population)\n",
    "        else:\n",
    "              print(f\"Population data not found for {city}.\")\n",
    "\n",
    "        # Search for elevation, extract and add to list\n",
    "        elevation = infobox.find(string=\"Elevation\")\n",
    "        if elevation:\n",
    "              elevation = elevation.find_next(\"td\").get_text().strip()\n",
    "              elevation = int(re.sub(r'\\D', '', elevation[:5]))\n",
    "              cities_dict[\"elevation_[m]\"].append(elevation)\n",
    "        else:\n",
    "              cities_dict[\"elevation_[m]\"].append(None)\n",
    "      else:\n",
    "        print(f\"Infobox not found for {city}.\")\n",
    "\n",
    "    else: \n",
    "      print(f\"error code {openweather_raw['cod']} in query for {city}\")\n",
    "\n",
    "  cities_df = pd.DataFrame(cities_dict)\n",
    "\n",
    "  cities_df[\"population\"].astype(int)\n",
    "\n",
    "  engine = create_engine(connection())\n",
    "  inspector = inspect(engine)\n",
    "  if 'cities' in inspector.get_table_names():\n",
    "    existing_data = pd.read_sql('cities', engine)\n",
    "    cities_df = cities_df[~cities_df['city_id'].isin(existing_data['city_id'])]\n",
    "  \n",
    "  cities_df.to_sql('cities',\n",
    "                con=engine,\n",
    "                if_exists='append',\n",
    "                index=False,\n",
    "                dtype={'lat': Float, 'lon': Float}\n",
    "                )\n",
    "    \n",
    "  return cities_df\n",
    "\n",
    "def push_weather_data_to_sql():\n",
    "\n",
    "  API_key = \"81f1a5b752c4569a954655d748508db5\"\n",
    "  cities = (pd.read_sql(\"cities\", con=connection()))[\"city\"]\n",
    "  country_code = (pd.read_sql(\"cities\", con=connection()))[\"country\"]\n",
    "  weather_dict = {\n",
    "      \"city_id\": [],\n",
    "      \"temp_[°C]\": [],\n",
    "      \"temp_(feels_like)_[°C]\": [], \n",
    "      \"main_weather\": [], \n",
    "      \"wind_speed_[m/s]\": [], \n",
    "      \"gust_speed_[m/s]\": [], \n",
    "      \"sight_distance_[m]\": [], \n",
    "      \"probability_of_precipitation_[%]\": [], \n",
    "      \"rain_last_3h_[mm]\": [], \n",
    "      \"snow_last_3h_[mm]\": [], \n",
    "      \"forecast_time\": [], \n",
    "      \"timestamp\": [] }\n",
    "    \n",
    "\n",
    "  for city in cities:\n",
    "\n",
    "    url = f\" https://api.openweathermap.org/data/2.5/forecast?q={city},{country_code}&appid={API_key}&units=metric\"\n",
    "    openweather_raw = requests.get(url).json()\n",
    "        \n",
    "    if openweather_raw[\"cod\"] == \"200\":\n",
    "\n",
    "      for i in range(openweather_raw[\"cnt\"]):\n",
    "        weather_dict[\"city_id\"].append(openweather_raw[\"city\"][\"id\"])\n",
    "        weather_dict[\"temp_[°C]\"].append(openweather_raw[\"list\"][i][\"main\"][\"temp\"])\n",
    "        weather_dict[\"temp_(feels_like)_[°C]\"].append(openweather_raw[\"list\"][i][\"main\"][\"feels_like\"])\n",
    "        weather_dict[\"main_weather\"].append(openweather_raw[\"list\"][i][\"weather\"][0][\"main\"])\n",
    "        weather_dict[\"wind_speed_[m/s]\"].append(openweather_raw[\"list\"][i][\"wind\"][\"speed\"])\n",
    "        weather_dict[\"gust_speed_[m/s]\"].append(openweather_raw[\"list\"][i][\"wind\"][\"gust\"])\n",
    "        try:\n",
    "          weather_dict[\"sight_distance_[m]\"].append(openweather_raw[\"list\"][i][\"visibility\"])\n",
    "        except:\n",
    "          weather_dict[\"sight_distance_[m]\"].append(None)\n",
    "        weather_dict[\"probability_of_precipitation_[%]\"].append(openweather_raw[\"list\"][i][\"pop\"]*100)\n",
    "        try:\n",
    "          weather_dict[\"rain_last_3h_[mm]\"].append(openweather_raw[\"list\"][i][\"rain\"][\"3h\"])\n",
    "        except:\n",
    "          weather_dict[\"rain_last_3h_[mm]\"].append(0)\n",
    "        try:\n",
    "          weather_dict[\"snow_last_3h_[mm]\"].append(openweather_raw[\"list\"][i][\"snow\"][\"3h\"])\n",
    "        except:\n",
    "          weather_dict[\"snow_last_3h_[mm]\"].append(0)\n",
    "        weather_dict[\"forecast_time\"].append(pd.to_datetime(openweather_raw[\"list\"][i][\"dt_txt\"]))\n",
    "        weather_dict[\"timestamp\"].append(pd.to_datetime(datetime.now().replace(microsecond=0)))\n",
    "      \n",
    "    else: \n",
    "      print(f\"error code {openweather_raw['cod']} in query for {city}\")\n",
    "                \n",
    "  weather_df = pd.DataFrame(weather_dict)\n",
    "\n",
    "  weather_df[\"snow_last_3h_[mm]\"].astype(float)\n",
    "  \n",
    "  weather_df.to_sql('weather',\n",
    "                if_exists='append',\n",
    "                con=connection(),\n",
    "                index=False)\n",
    "\n",
    "  return weather_df\n",
    "\n",
    "\n",
    "def push_airport_data_to_sql():\n",
    "\n",
    "  #assert len(latitudes) == len(longitudes)\n",
    "    \n",
    "  latitudes = (pd.read_sql(\"cities\", con=connection()))[\"lat\"]\n",
    "  longitudes = (pd.read_sql(\"cities\", con=connection()))[\"lon\"]\n",
    "\n",
    "  list_for_df = []\n",
    "\n",
    "  for index, value in enumerate(latitudes):\n",
    "\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/airports/search/location/{value}/{longitudes[index]}/km/50/10\"\n",
    "\n",
    "    querystring = {\"withFlightInfoOnly\":\"true\"}\n",
    "\n",
    "    headers = {\n",
    "    \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\",\n",
    "    \"X-RapidAPI-Key\": \"14a44098c8mshe4536a007985112p1e3b4bjsn8fd805eb6bd4\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    list_for_df.append(pd.json_normalize(response.json()['items']))\n",
    "\n",
    "    airports_df = pd.concat(list_for_df, ignore_index=True)\n",
    "\n",
    "    engine = create_engine(connection())\n",
    "    inspector = inspect(engine)\n",
    "    if 'airports' in inspector.get_table_names():\n",
    "      existing_data = pd.read_sql('airports', engine)\n",
    "      airports_df = airports_df[~airports_df['iata'].isin(existing_data['iata'])]\n",
    "\n",
    "    airports_df.to_sql('airports',\n",
    "              if_exists='append',\n",
    "              con=connection(),\n",
    "              index=False)\n",
    "\n",
    "  return airports_df\n",
    "\n",
    "\n",
    "def push_cities_airports_to_sql():\n",
    "\n",
    "  cities_df = pd.read_sql(\"cities\", con=connection())\n",
    "  airports_df = pd.read_sql(\"airports\", con=connection())\n",
    "\n",
    "  cities_airports_df = (pd.merge(cities_df, airports_df, left_on=\"city\", right_on=\"municipalityName\", how=\"left\"))[[\"city_id\",\"iata\"]]\n",
    "\n",
    "  engine = create_engine(connection())\n",
    "  inspector = inspect(engine)\n",
    "  if 'cities_airports' in inspector.get_table_names():\n",
    "      existing_data = pd.read_sql('cities_airports', engine)\n",
    "      cities_airports_df = cities_airports_df[~cities_airports_df['city_id'].isin(existing_data['city_id'])]\n",
    "\n",
    "  cities_airports_df.to_sql('cities_airports',\n",
    "          if_exists='append',\n",
    "          con=connection(),\n",
    "          index=False)\n",
    "  \n",
    "  return cities_airports_df\n",
    "\n",
    "\n",
    "def push_flights_datad_to_sql():\n",
    "\n",
    "\tiata_list = (pd.read_sql(\"cities_airports\", con=connection()))[\"iata\"]\n",
    "\n",
    "\ttomorrow_date = datetime.now() + timedelta(days=1)\n",
    "\tstart_time_morning = datetime(tomorrow_date.year, tomorrow_date.month, tomorrow_date.day, 0, 0).strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\tend_time_morning = datetime(tomorrow_date.year, tomorrow_date.month, tomorrow_date.day, 12, 0).strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\tstart_time_afternoon = datetime(tomorrow_date.year, tomorrow_date.month, tomorrow_date.day, 12, 0).strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\tend_time_afternoon = datetime(tomorrow_date.year, tomorrow_date.month, tomorrow_date.day, 23, 59, 59).strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\t\n",
    "\tquerystring = {\"withLeg\":\"false\",\"direction\":\"Arrival\",\"withCancelled\":\"false\",\"withCodeshared\":\"false\", \"withCargo\":\"false\",\"withPrivate\":\"false\",\"withLocation\":\"false\"}\n",
    "\n",
    "\theaders = {\n",
    "\t\t\"X-RapidAPI-Key\": \"14a44098c8mshe4536a007985112p1e3b4bjsn8fd805eb6bd4\",\n",
    "\t\t\"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "\t}\n",
    "\n",
    "\tflights_dict = {\n",
    "\t\t\"flight_num\": [],\n",
    "\t\t\"departure_iata\": [], \n",
    "\t\t\"arrival_iata\": [], \n",
    "\t\t\"arrival_time\": []}\n",
    "\n",
    "\tfor iata in iata_list:\n",
    "\t\tfor start_time, end_time in [(start_time_morning, end_time_morning), (start_time_afternoon, end_time_afternoon)]:\n",
    "\t\t\n",
    "\t\t\turl = f\"https://aerodatabox.p.rapidapi.com/flights/airports/iata/{iata}/{start_time}/{end_time}\"\n",
    "\t\t\tflight_data_raw = requests.get(url, headers=headers, params=querystring).json()\n",
    "\n",
    "\t\t\tfor arrival in flight_data_raw[\"arrivals\"]:\n",
    "\t\t\t\tdeparture_iata = arrival[\"movement\"][\"airport\"].get(\"iata\", \"Unknown\")\n",
    "\t\t\t\tarrival_time = arrival[\"movement\"].get(\"revisedTime\", {}).get(\"local\") or arrival[\"movement\"][\"scheduledTime\"][\"local\"]\n",
    "\t\t\t\tflights_dict[\"flight_num\"].append(arrival[\"number\"])\n",
    "\t\t\t\tflights_dict[\"departure_iata\"].append(departure_iata)\n",
    "\t\t\t\tflights_dict[\"arrival_iata\"].append(iata)\n",
    "\t\t\t\tflights_dict[\"arrival_time\"].append(datetime.strptime(arrival_time, \"%Y-%m-%d %H:%M%z\").strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\tflights_df = pd.DataFrame(flights_dict)\n",
    "\n",
    "\tengine = create_engine(connection())\n",
    "\tinspector = inspect(engine)\n",
    "\n",
    "\tif 'flights' in inspector.get_table_names():\n",
    "\t\texisting_data = pd.read_sql('flights', engine)\n",
    "\t\tflights_df = flights_df[~flights_df['flight_num'].isin(existing_data['flight_num'])]\n",
    "\n",
    "\tflights_df.to_sql('flights',\n",
    "\t\t\t\t\tcon=engine,\n",
    "\t\t\t\t\tif_exists='append',\n",
    "\t\t\t\t\tindex=False\n",
    "\t\t\t\t\t)\n",
    "\treturn flights_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'successfully updated'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==2.1.4\n",
      "requests==2.31.0\n",
      "re==2.2.1\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(f'{m.__name__}=={m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
